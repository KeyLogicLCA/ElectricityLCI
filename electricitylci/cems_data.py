#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# cems_data.py
#
##############################################################################
# REQUIRED MODULES
##############################################################################
import os
import logging
import time

import pandas as pd
import requests

from electricitylci.globals import API_SLEEP
from electricitylci.globals import paths
from electricitylci.globals import output_dir
from electricitylci.globals import US_STATES


##############################################################################
# MODULE DOCUMENTATION
##############################################################################
__doc__ = """
Retrieve data from EPA CEMS daily zipped CSVs.

This module pulls data from EPA's published CSV files, which are utilized
in ampd_plant_emissions.py.

In the 2023 update, the workflow is to apply for an EPA Data API key

- https://www.epa.gov/power-sector/cam-api-portal#/api-key-signup

Then, run the following:

.. code: python

    >>> from electricitylci.cems_data import build_cems_df
    >>> df = build_cems_df(2016, use_api=True)

This will trigger the 48 lower states (plus DC) zip files to be downloaded.
Subsequent calls of ElectricityLCI will search for these local files before
triggering another API call, thus avoiding the API key input.

EPA CEMS state data are stored in separate zip archives in sub-directories
located in ElectricityLCI's local data directory, found in the following
address: ``electricitylci.globals.output_dir``.

---

The legacy methods once found in this module were originally taken from
"The Public Utility Data Liberation Project" (PUDL).
https://catalystcoop-pudl.readthedocs.io/en/latest/index.html

Copyright 2016-2024 Catalyst Cooperative and the Climate Policy Initiative
CC-BY-4.0

In the current release, the PUDL methods are replaced with EPA's API:
https://github.com/USEPA/ElectricityLCI/issues/207#issuecomment-1751075194

Last edited:
    2024-02-26
"""


##############################################################################
# GLOBALS
##############################################################################
CEMS_STATES = {
    k: v for k, v in US_STATES.items() if v not in [
        'Alaska',
        'American Samoa',
        'Guam',
        'Hawaii',
        'Northern Mariana Islands',
        'National',
        'Puerto Rico',
        'Virgin Islands']
}

CEMS_COL_NAMES = {
    'GLOAD (MWh)': 'gross_load_mwh',
    'SO2_MASS (tons)': 'so2_mass_tons',
    'NOX_MASS (tons)': 'nox_mass_tons',
    'SUM_OP_TIME': 'sum_op_time',
    'COUNT_OP_TIME': 'count_op_time'
}


##############################################################################
# FUNCTIONS
##############################################################################
def _write_cems_api(data, file_path):
    """Helper method for writing the API data frames to file.

    This is in support of repeated usage of ElectricityLCI to avoid
    running API calls (and inputting the API key) each and every time.

    Parameters
    ----------
    data : pandas.DataFrame
        A data frame with CEMS data as read from API and converted from JSON.
    file_path : str
        A path to the zip CSV file (e.g., as generated by :func:`path`).
        Warns if file already exists, as the default is to overwrite.

    Raises
    ------
    TypeError
        If other than data frame data object is received.
    """
    if os.path.exists(file_path):
        logging.warning("Overwriting existing CEMS CSV file!")

    if not isinstance(data, pd.DataFrame):
        raise TypeError("Expected pandas data frame, received %s" % type(data))

    file_dir = os.path.dirname(file_path)
    if not os.path.isdir(file_dir):
        logging.info("Creating output directory for CEMS data: %s" % file_dir)
        try:
            os.makedirs(file_dir, exist_ok=True)
        except Exception as e:
            logging.error("Failed to create folder, %s" % file_dir)
            logging.error("%s" % str(e))

    try:
        # Should infer zip compression from file extension.
        data.to_csv(file_path, index=False)
    except Exception as e:
        logging.error("Failed to write CEMS data to CSV: %s" % file_path)
        logging.error("%s" % str(e))
    else:
        logging.info("Saved CEMS data to file, %s" % file_path)


def build_cems_df(year, use_api=True):
    """Build the CEMS data frame.

    Download the CEMS CSV zip files for each state for a given year,
    then open each one and append it to a pandas data frame, and
    aggregate the data by facility.

    Parameters
    ----------
    year : int
        A valid year for EPA CEMS data (e.g., 1995 to present).
    use_api : bool, optional
        Whether to use the EPA data API; sign-up free here:
        https://www.epa.gov/power-sector/cam-api-portal#/api-key-signup

    Returns
    -------
    pandas.DataFrame :
        A data frame with the annual CEMS data by facility.

    Raises
    ------
    OSError :
        When use API is set to false.
        Legacy methods are not longer supported.

    Examples
    --------
    >>> df = build_cems_df(2016)
    >>> list(df.columns)
    ['state',
     'plant_id_eia',
     'gross_load_mwh',
     'steam_load_1000_lbs',
     'so2_mass_tons',
     'nox_mass_tons',
     'co2_mass_tons',
     'heat_content_mmbtu']
    >>> len(df)
    1463
    >>> df.head()
      state  plant_id_eia  facility_id  ...  co2_mass_tons  heat_content_mmbtu
    0    AL             3            1  ...    8235782.477        1.055546e+08
    1    AL             7            3  ...     162134.726        2.734769e+06
    2    AL             8            4  ...    6140953.861        5.985333e+07
    3    AL            10            5  ...    1055231.747        1.354952e+07
    4    AL            26            6  ...    4981736.725        5.059296e+07

    Notes
    -----
    The same data can be accessed using EPA's CAMPD custom data download tool,
    which is available here:

    - https://campd.epa.gov/data/custom-data-download

    Set the following conditions in the query builder:

    - Data Type:

        - Data Type: Emissions
        - Data Subtype: Annual Emissions
        - Aggregation: Facility

    - Filters:

        - Time period: 2016

    Then click "Preview Data" and download the CSV.
    """
    states = CEMS_STATES.keys()

    if not use_api:
        raise OSError("EPA CEMS data only available through API!")
    raw_dfs = extract(
        epacems_years=[year],
        states=states,
        use_api=use_api
    )
    summary_df = process_cems_dfs(raw_dfs)
    return summary_df


def extract(epacems_years, states, use_api=True):
    """Extract the EPA CEMS hourly data.

    This function is the main function of this file. It returns a generator
    for extracted DataFrames.

    Parameters
    ----------
    epacems_years : list
        List of years.
    states : list
        List of states.
    use_api : bool, optional
        Option to by-pass the FTP download.
        Triggers input for API key, available for free at:
        https://www.epa.gov/power-sector/cam-api-portal#/api-key-signup

    Returns
    -------
    list
    """
    logging.info("Extracting EPA CEMS data...")
    dfs = []
    api_key = None
    new_api = "https://www.epa.gov/power-sector/cam-api-portal#/api-key-signup"

    for year in epacems_years:
        # The keys of the us_states dictionary are the state abbrevs
        for state in states:
            # Add API support
            if use_api:
                # HOTFIX: add local file support [2023-11-17; TWD]
                c_file = path("epacems", year=year, state=state)
                if os.path.exists(c_file):
                    logging.info(
                        "Found CEMS data file for %s %s" % (state, year))
                    tmp_df = pd.read_csv(c_file)
                else:
                    if api_key is None:
                        api_key = input("Enter EPA API key: ")
                        api_key = api_key.strip()
                        if api_key == "":
                            logging.warning(
                                "No API key given!"
                                f"Sign up here: {new_api}"
                            )
                    tmp_df = read_cems_api(api_key, year, state)

                # HOTFIX: don't add empty data frames
                records = len(tmp_df)
                logging.debug("%s %s: %d records" % (state, year, records))
                if records > 0:
                    dfs.append(tmp_df)
                time.sleep(API_SLEEP)
            else:
                raise OSError("EPA CEMS data only available through API!")
    return dfs


def path(source, year=0, qtr=None, state=None, file_=True):
    """Construct a variety of local datastore paths for a given data source.

    PUDL expects the original data it ingests to be organized in a particular
    way. This function allows you to easily construct useful paths that refer
    to various parts of the data store, by specifying the data source you are
    interested in, and optionally the year of data you're seeking, as well as
    whether you want the originally downloaded files for that year, or the
    directory in which a given year's worth of data for a particular data
    source can be found.

    Parameters
    ----------
    source : str
        A string indicating which data source we are going to be
        downloading. Currently only 'epacems' is handled.
    year : int, optional
        The year of data that the returned path should pertain to.
        Must be within the range of valid data years, which is specified
        for each data source in pudl.constants.data_years, unless year is
        set to zero, in which case only the top level directory for the
        data source specified in source is returned.
    qtr : int, optional
        The quarter (e.g., 1--4). Defaults to none.
    file_ : bool, optional
        If True, return the full path to the originally
        downloaded file specified by the data source and year.
        If file is true, year must not be set to zero, as a year is
        required to specify a particular downloaded file.

    Returns
    -------
    str :
        The path to the requested resource within the local PUDL datastore.

    Raises
    ------
    ValueError :
        For non 'epacems' data source requests.
    """
    if file_:
        assert year != 0, \
            "Non-zero year required to generate full datastore file path."

    if source == 'epacems':
        dstore_path = paths.local_path
        if year != 0:
            dstore_path = os.path.join(dstore_path, 'epacems{}'.format(year))
    else:
        raise ValueError(
            "Bad data source '{}' requested.".format(source)
        )

    # Handle month and state, if they're provided
    if qtr is None:
        qtr_str = ''
    else:
        qtr_str = str(qtr)
    if state is None:
        state_str = ''
    else:
        state_str = state.lower()

    # Current naming convention requires the name of the directory to which
    # an original data source is downloaded to be the same as the basename
    # of the file itself.
    if (file_ and source not in ['mshamines', 'mshaops', 'mshaprod']):
        basename = os.path.basename(dstore_path)
        # For all the non-CEMS data, state_str and month_str are '',
        # but this should work for other monthly data too.
        dstore_path = os.path.join(
            dstore_path, f"{basename}{state_str}{qtr_str}.zip"
        )
    return dstore_path


def process_cems_dfs(df_list):
    """Concatenate a list of quarterly state CEMS data frames and aggregate
    by facility.

    Parameters
    ----------
    df_list : list
        A list of pandas.DataFrame objects.

    Returns
    -------
    pandas.DataFrame
        A concatenated and aggregated data frame.
        Columns include:

        - 'state' - two-letter state abbreviation
        - 'plant_id_eia' - the plant ID used elsewhere in eLCI
        - 'gross_load_mwh'
        - 'steam_load_1000_lbs'
        - 'so2_mass_tons'
        - 'nox_mass_tons'
        - 'co2_mass_tons'
        - 'heat_content_mmbtu'
    """
    df = pd.concat(df_list)
    df.rename(columns=CEMS_COL_NAMES, inplace=True)
    cols_to_sum = [
        'gross_load_mwh',
        'steam_load_1000_lbs',
        'so2_mass_tons',
        'nox_mass_tons',
        'co2_mass_tons',
        'heat_content_mmbtu'
    ]
    # HOTFIX: remove 'facility_id' from groupby
    new_df = df.groupby(
        by=['state', 'plant_id_eia'],
        group_keys=False,
        as_index=False
    )[cols_to_sum].sum()
    return new_df


def read_cems_api(api_key, year, state=None, force=False):
    """Read CEMS annual apportioned emissions from new EPA API.

    Method checks local directory for file existence and prioritizes
    reading from file before calling the API unless force is set to true.

    Parameters
    ----------
    api_key : str
        EPA data API key
    year : int
        Data year (e.g., 2016)
    state : str, optional
        Two-character state abbreviation (e.g., "VA"), by default None
    force : bool, optional
        Whether to force reading from API (rather than check for local copy).
        Defaults to false.

    Returns
    -------
    pandas.DataFrame
        CEMS data frame.

    Raises
    ------
    ValueError
        For missing API key.
    OSError
        For unexpected API errors.
    """
    # Use the annual apportioned emissions API URL:
    s_url = (
        "https://api.epa.gov/easey/streaming-services/emissions/"
        "apportioned/annual/by-facility"
    )

    # Keep column naming consistent with legacy code:
    c_map = {
        'stateCode': 'state',
        'facilityName': 'facility_name',
        'facilityId': 'plant_id_eia',
        'year': 'year',
        'grossLoad': 'gross_load_mwh',
        'steamLoad': 'steam_load_1000_lbs',
        'so2Mass': 'so2_mass_tons',
        'co2Mass': 'co2_mass_tons',
        'noxMass': 'nox_mass_tons',
        'heatInput': 'heat_content_mmbtu'
    }
    # Prepare the empty return data frame
    tmp_df = pd.DataFrame(columns=list(c_map.values()))

    # HOTFIX: add local file checking [2023-11-17; TWD]
    c_file = path("epacems", year=year, state=state)
    if os.path.exists(c_file) and not force:
        logging.info("Found CEMS data file for %s %s" % (state, year))
        tmp_df = pd.read_csv(c_file)
    else:
        # Check that API key exists
        if api_key is None or api_key == "":
            raise ValueError("Missing Clean Air Markets API key!")

        # Prepare the API parameters
        params = {'api_key': api_key, 'year': year, 'stateCode': state}
        try:
            r = requests.get(s_url, params=params)
        except:
            raise OSError("Unexpected error during EPA data API call!")
        else:
            if r.ok:
                tmp_df = pd.DataFrame.from_dict(r.json()).rename(columns=c_map)
                _write_cems_api(tmp_df, c_file)
            else:
                # This catches incorrect API keys or bad parameters
                e_msg = r.json().get("message", ["",])
                if isinstance(e_msg, list):
                    e_msg = "".join(e_msg)
                logging.warning(
                    "Failed to retrieve data for %s %s! %s" % (
                        state, year, e_msg)
                )

    return tmp_df


##############################################################################
# MAIN
##############################################################################
if __name__ == '__main__':
    year = 2016
    df = build_cems_df(year)
    df.to_csv(f'{output_dir}/cems_emissions_{year}.csv')
